{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f17d610e-7f3b-4a1c-98dc-c2bd7ed31010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.4.0\n",
      "Transformers version: 4.44.0\n",
      "Sentence Transformers version: 3.0.1\n",
      "LangChain version: 0.2.14\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import sentence_transformers\n",
    "import langchain\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"Transformers version:\", transformers.__version__)\n",
    "print(\"Sentence Transformers version:\", sentence_transformers.__version__)\n",
    "print(\"LangChain version:\", langchain.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3df38105-93bd-483c-b8c7-099dfd2f646a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1579\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Update this path to the directory where your CVE JSON files are located\n",
    "cve_data_path = 'F:\\\\cvelistV5-main\\\\cvelistV5-main\\\\cves\\\\1999'\n",
    "\n",
    "cve_documents = []\n",
    "for root, dirs, files in os.walk(cve_data_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.json'):\n",
    "            with open(os.path.join(root, file), 'r', encoding='utf-8') as f:\n",
    "                cve_content = json.load(f)\n",
    "                \n",
    "                # Extract only the relevant fields\n",
    "                cve_metadata = cve_content.get('cveMetadata', {})\n",
    "                containers = cve_content.get('containers', {}).get('cna', {})\n",
    "\n",
    "                # Get the relevant fields\n",
    "                cve_id = cve_metadata.get('cveId', 'N/A')\n",
    "                date_published = cve_metadata.get('datePublished', 'N/A')\n",
    "                date_updated = cve_metadata.get('dateUpdated', 'N/A')\n",
    "                descriptions = containers.get('descriptions', [])\n",
    "                affected = containers.get('affected', [])\n",
    "\n",
    "                # Structure the extracted data\n",
    "                relevant_data = {\n",
    "                    'cveId': cve_id,\n",
    "                    'datePublished': date_published,\n",
    "                    'dateUpdated': date_updated,\n",
    "                    'descriptions': descriptions,\n",
    "                    'affected': affected\n",
    "                }\n",
    "\n",
    "                # Create Document with page_content and metadata\n",
    "                cve_documents.append(Document(page_content=json.dumps(relevant_data), metadata={\"source\": file}))\n",
    "\n",
    "data = cve_documents\n",
    "\n",
    "# Print the number of documents loaded\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4eacd05-f10b-49c9-8d7c-43a8438948d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of chunks: 1579\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Split data into smaller chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000) # Adjust chunk size to avoid sequence length issues\n",
    "docs = text_splitter.split_documents(data)\n",
    "\n",
    "print(\"Total number of chunks:\", len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33c5967c-4d43-4cee-948a-e439a1ee87ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cve-index\n",
      "Top relevant document: {'source': 'CVE-1999-0014.json'}\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Initialize Pinecone with the API key\n",
    "pc = Pinecone(api_key=\"xxxxxx\")\n",
    "\n",
    "# Connect to the existing Pinecone index\n",
    "index = pc.Index(\"cve-index\")\n",
    "\n",
    "# All commented out portions are one time operations - like creating a Pinecone index, upserting the vector embeddings into the index\n",
    "\n",
    "# pc.create_index(\n",
    "#     name='cve-index',\n",
    "#     dimension=768,\n",
    "#     metric='euclidean',\n",
    "#     deletion_protection='enabled',\n",
    "#     spec=ServerlessSpec(\n",
    "#         cloud='aws',\n",
    "#         region='us-east-1'\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# Testing connection to index by listing indexes - output: cve-index\n",
    "for idx in pc.list_indexes():\n",
    "    print(idx['name'])\n",
    "\n",
    "# Initialize the embeddings model - using sentence-transformers from Transformers library of HuggingFace\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "# Use only a smaller subset of documents for testing\n",
    "# small_docs = docs[:20]\n",
    "\n",
    "# Convert the small subset of documents into embeddings and upsert them into the Pinecone index\n",
    "# vectors = [embeddings.embed_query(doc.page_content) for doc in small_docs]\n",
    "# upsert_data = [(str(i), vectors[i], {\"text\": doc.page_content, **doc.metadata}) for i, doc in enumerate(small_docs)]\n",
    "\n",
    "# Upsert the vectors into Pinecone\n",
    "# upsert_response = index.upsert(\n",
    "#     vectors=upsert_data,\n",
    "#     # namespace=\"cve-namespace\"\n",
    "# )\n",
    "\n",
    "# Function to answer any question using Pinecone index\n",
    "def answer_question(question):\n",
    "    # Convert the question into an embedding\n",
    "    question_embedding = embeddings.embed_query(question)\n",
    "    \n",
    "    # Perform a similarity search in the Pinecone index\n",
    "    query_response = index.query(\n",
    "        vector=question_embedding,\n",
    "        top_k=5,  # Adjust top_k to the number of results you want\n",
    "        include_values=True,\n",
    "        include_metadata=True\n",
    "    )\n",
    "    \n",
    "    # Print the most relevant document (or chunk) found\n",
    "    print(\"Top relevant document:\", query_response['matches'][0]['metadata'])\n",
    "\n",
    "# Example interaction\n",
    "question = \"via dtappgather program in CD\"\n",
    "answer_question(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "051829a6-3e3e-4d14-b855-47470aea4a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'What is the vulnerability related to dtappgather program in CD?', 'result': 'According to the provided context, the vulnerability related to the dtappgather program in CDE is unauthorized privileged access or denial of service.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.embeddings import HuggingFaceHubEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEndpointEmbeddings\n",
    "\n",
    "# Initialize the LLM with Groq API\n",
    "llm = ChatGroq(\n",
    "    model=\"llama3-70b-8192\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    api_key=\"xxxxxx\"\n",
    ")\n",
    "\n",
    "# Define a prompt template\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you do not know the answer.\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "\n",
    "# Create a retriever using the Pinecone vector store - it fetches the relevant documents based on similarity search.\n",
    "db = PineconeVectorStore(\n",
    "    index=index,\n",
    "    embedding=embeddings\n",
    ")\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "# Create a RetrievalQA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")\n",
    "\n",
    "# Function to generate a response using the LLM\n",
    "def answer_question(prompt):\n",
    "    try:\n",
    "        # When qa_chain.invoke(prompt) method is called, the 'prompt' is converted into vector embeddings within the RetrievalQA chain. \n",
    "        # Then a similairity search is conducted by the retriever within the Pinecone index to find results that are similar to the prompt. \n",
    "        # These search results are known as 'context'.\n",
    "        # The QA_CHAIN_PROMPT template is used to combine the 'context' and the original 'prompt'.\n",
    "        # This constructed prompt is sent to LLM to generate a response.\n",
    "        response = qa_chain.invoke(prompt)\n",
    "    except Exception as e:\n",
    "        response = f\"Error: {e}\"\n",
    "    return response\n",
    "\n",
    "# Example interaction\n",
    "print(answer_question(\"What is the vulnerability related to dtappgather program in CD?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd79e390-5565-4684-a6c8-9e6151b65c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
